{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FeatureGenerator import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from helpers import *\n",
    "\n",
    "\n",
    "class SentimentFeatureGenerator(FeatureGenerator):\n",
    "\n",
    "\n",
    "    def __init__(self, name='sentimentFeatureGenerator'):\n",
    "        super(SentimentFeatureGenerator, self).__init__(name)\n",
    "\n",
    "\n",
    "    def process(self, df):\n",
    "\n",
    "        print('generating sentiment features')\n",
    "        print('for headline')\n",
    "        \n",
    "        n_train = df[~df['target'].isnull()].shape[0]\n",
    "        n_test = df[df['target'].isnull()].shape[0]\n",
    "\n",
    "        # calculate the polarity score of each sentence then take the average\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        def compute_sentiment(sentences):\n",
    "            result = []\n",
    "            for sentence in sentences:\n",
    "                vs = sid.polarity_scores(sentence)\n",
    "                result.append(vs)\n",
    "            return pd.DataFrame(result).mean()\n",
    "        \n",
    "        #df['headline_sents'] = df['Headline'].apply(lambda x: sent_tokenize(x.decode('utf-8')))\n",
    "        df['headline_sents'] = df['Headline'].apply(lambda x: sent_tokenize(x))\n",
    "        df = pd.concat([df, df['headline_sents'].apply(lambda x: compute_sentiment(x))], axis=1)\n",
    "        df.rename(columns={'compound':'h_compound', 'neg':'h_neg', 'neu':'h_neu', 'pos':'h_pos'}, inplace=True)\n",
    "        #print 'df:'\n",
    "        #print df\n",
    "        #print df.columns\n",
    "        #print df.shape\n",
    "        headlineSenti = df[['h_compound','h_neg','h_neu','h_pos']].values\n",
    "        print('headlineSenti.shape:')\n",
    "        print(headlineSenti.shape)\n",
    "        \n",
    "        headlineSentiTrain = headlineSenti[:n_train, :]\n",
    "        outfilename_hsenti_train = \"train.headline.senti.pkl\"\n",
    "        with open(outfilename_hsenti_train, \"wb\") as outfile:\n",
    "            pickle.dump(headlineSentiTrain, outfile, -1)\n",
    "        print('headline sentiment features of training set saved in %s' % outfilename_hsenti_train)\n",
    "        \n",
    "        if n_test > 0:\n",
    "            # test set is available\n",
    "            headlineSentiTest = headlineSenti[n_train:, :]\n",
    "            outfilename_hsenti_test = \"test.headline.senti.pkl\"\n",
    "            with open(outfilename_hsenti_test, \"wb\") as outfile:\n",
    "                pickle.dump(headlineSentiTest, outfile, -1)\n",
    "            print('headline sentiment features of test set saved in %s' % outfilename_hsenti_test)\n",
    "        \n",
    "        print('headine senti done')\n",
    "        \n",
    "        #return 1\n",
    "\n",
    "        print('for body')\n",
    "        #df['body_sents'] = df['articleBody'].map(lambda x: sent_tokenize(x.decode('utf-8')))\n",
    "        df['body_sents'] = df['articleBody'].map(lambda x: sent_tokenize(x))\n",
    "        df = pd.concat([df, df['body_sents'].apply(lambda x: compute_sentiment(x))], axis=1)\n",
    "        df.rename(columns={'compound':'b_compound', 'neg':'b_neg', 'neu':'b_neu', 'pos':'b_pos'}, inplace=True)\n",
    "        #print 'body df:'\n",
    "        #print df\n",
    "        #print df.columns\n",
    "        bodySenti = df[['b_compound','b_neg','b_neu','b_pos']].values\n",
    "        print('bodySenti.shape:')\n",
    "        print(bodySenti.shape)\n",
    "        \n",
    "        bodySentiTrain = bodySenti[:n_train, :]\n",
    "        outfilename_bsenti_train = \"train.body.senti.pkl\"\n",
    "        with open(outfilename_bsenti_train, \"wb\") as outfile:\n",
    "            pickle.dump(bodySentiTrain, outfile, -1)\n",
    "        print('body sentiment features of training set saved in %s' % outfilename_bsenti_train)\n",
    "        \n",
    "        if n_test > 0:\n",
    "            # test set is available\n",
    "            bodySentiTest = bodySenti[n_train:, :]\n",
    "            outfilename_bsenti_test = \"test.body.senti.pkl\"\n",
    "            with open(outfilename_bsenti_test, \"wb\") as outfile:\n",
    "                pickle.dump(bodySentiTest, outfile, -1)\n",
    "            print('body sentiment features of test set saved in %s' % outfilename_bsenti_test)\n",
    "\n",
    "        print('body senti done')\n",
    "\n",
    "        return 1\n",
    "\n",
    "\n",
    "    def read(self, header='train'):\n",
    "\n",
    "        filename_hsenti = \"%s.headline.senti.pkl\" % header\n",
    "        with open(filename_hsenti, \"rb\") as infile:\n",
    "            headlineSenti = pickle.load(infile)\n",
    "\n",
    "        filename_bsenti = \"%s.body.senti.pkl\" % header\n",
    "        with open(filename_bsenti, \"rb\") as infile:\n",
    "            bodySenti = pickle.load(infile)\n",
    "        np.save('senti_headline_body_test', [headlineSenti, bodySenti])\n",
    "        print('headlineSenti.shape:')\n",
    "        print(headlineSenti.shape)\n",
    "        #print type(headlineSenti)\n",
    "        print('bodySenti.shape:')\n",
    "        print(bodySenti.shape)\n",
    "        #print type(bodySenti)\n",
    "\n",
    "        return [headlineSenti, bodySenti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SentimentFeatureGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlineSenti.shape:\n",
      "(25413, 4)\n",
      "bodySenti.shape:\n",
      "(25413, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.7906,  0.4   ,  0.6   ,  0.    ],\n",
       "        [-0.6808,  0.454 ,  0.395 ,  0.151 ],\n",
       "        [-0.0772,  0.195 ,  0.629 ,  0.176 ],\n",
       "        ..., \n",
       "        [ 0.7773,  0.121 ,  0.451 ,  0.428 ],\n",
       "        [ 0.7773,  0.121 ,  0.451 ,  0.428 ],\n",
       "        [ 0.7773,  0.121 ,  0.451 ,  0.428 ]]),\n",
       " array([[-0.4161375 ,  0.212125  ,  0.7465    ,  0.0415    ],\n",
       "        [ 0.08677778,  0.005     ,  0.96411111,  0.03088889],\n",
       "        [-0.40861429,  0.18785714,  0.76592857,  0.04628571],\n",
       "        ..., \n",
       "        [-0.05295769,  0.05730769,  0.89613462,  0.04653846],\n",
       "        [-0.09127593,  0.1167037 ,  0.80825926,  0.07503704],\n",
       "        [ 0.11387778,  0.0602963 ,  0.85044444,  0.08925926]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.read('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
