{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Statements\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import html\n",
    "import re\n",
    "import string\n",
    "from fncbaseline.utils import dataset, generate_test_splits, score\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.summarization import summarize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from fncbaseline.utils import dataset, generate_test_splits, score\n",
    "from fncbaseline import feature_engineering\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n",
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_dataset = dataset.DataSet()\n",
    "test_dataset = dataset.DataSet('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "\n",
    "global_map = dict()\n",
    "SUMMARY_LEN = 100\n",
    "\n",
    "#Variables for Preprocessing\n",
    "do_summary = False\n",
    "head_stop,head_summary = True, False\n",
    "body_stop,body_summary = True, False\n",
    "\n",
    "# Embedding Dimension\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "# Head and body max\n",
    "max_head = 30\n",
    "max_body = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Preprocess the data\n",
    "\n",
    "def preprocess(text,stop,do_summ):\n",
    "    g_text = text\n",
    "    if g_text in global_map :\n",
    "        return global_map[g_text]\n",
    "    \n",
    "    if do_summ:\n",
    "        temp = re.sub(r'[.]+',\"\\n\",text)\n",
    "        if len(temp.split()) > SUMMARY_LEN:\n",
    "            text = summarize(temp,word_count = SUMMARY_LEN)\n",
    "              \n",
    "    text = html.unescape(text)\n",
    "    text = text.replace(\"\\\\n\",\" \")\n",
    "    text = text.replace(\"_NEG\",\"\")\n",
    "    text = text.replace(\"_NEGFIRST\", \"\")\n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "    text = re.sub(r\"\\*\", \"\", text)\n",
    "    text = re.sub(r\"\\'s\", \"\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\",\", \"\", text)\n",
    "    text = re.sub(r\"!\", \" !\", text)\n",
    "    text = re.sub(r\"\\(\", \"\", text)\n",
    "    text = re.sub(r\"\\)\", \"\", text)\n",
    "    text = re.sub(r\"\\?\", \" ?\", text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]',' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]',' ',text)\n",
    "    text = re.sub(\"\\d+\", \" \", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = text.rstrip(',|.|;|:|\\'|\\\"')\n",
    "    text = text.lstrip('\\'|\\\"')\n",
    "    if stop:\n",
    "        temp = remove_stopwords(text.strip().lower())\n",
    "        global_map[g_text] = temp\n",
    "    else:\n",
    "        temp = (text.strip().lower())\n",
    "        global_map[g_text] = temp\n",
    "    return global_map[g_text]\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    temp = stopwords.words('english')\n",
    "    split_text = \\\n",
    "    [word for word in text.split()\n",
    "        if word not in temp]\n",
    "    return \" \".join(split_text)\n",
    "\n",
    "def create_total_text(dataset,isStance,total_text):\n",
    "    if isStance:\n",
    "        for stance in dataset.stances:\n",
    "            total_text.append(preprocess(stance['Headline'],head_stop,head_summary))\n",
    "    else:\n",
    "        for article_id in dataset.articles:\n",
    "            total_text.append(preprocess(dataset.articles[article_id],body_stop,body_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49972\n",
      "51655\n",
      "77068\n",
      "77972\n"
     ]
    }
   ],
   "source": [
    "# Total Dataset \n",
    "total_text = list()\n",
    "create_total_text(train_dataset,True,total_text)\n",
    "print(len(total_text)) #sanity check\n",
    "create_total_text(train_dataset,False,total_text)\n",
    "print(len(total_text)) #sanity check\n",
    "create_total_text(test_dataset,True,total_text)\n",
    "print(len(total_text)) #sanity check\n",
    "create_total_text(test_dataset,False,total_text)\n",
    "print(len(total_text)) #sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77972\n",
      "28378\n"
     ]
    }
   ],
   "source": [
    "# Fiting a tokenizer on it\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(total_text)\n",
    "word_index = t.word_index\n",
    "print(t.document_count)\n",
    "vocab_size = len(t.word_counts)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_name = 'embedding_matrix_w2v'\n",
    "create_w2vec = False\n",
    "if do_summary:\n",
    "    temp_name+=\"_summary.npy\"\n",
    "else:\n",
    "    temp_name+=\"_no_summary.npy\"\n",
    "if create_w2vec:\n",
    "    \n",
    "    w2v_DIR = \"./fnc-1/GoogleNews-vectors-negative300.txt\"\n",
    "    embeddings_index = {}\n",
    "    f = open(GLOVE_DIR)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print ('Read Word2Vec and Made Dict')\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_size + 1, EMBEDDING_DIM))\n",
    "    number_found =0\n",
    "    number_not_found = 0\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            number_found+=1\n",
    "        else:\n",
    "            #print (word)\n",
    "            number_not_found+=1\n",
    "\n",
    "    print(number_found)\n",
    "    print(number_not_found)\n",
    "    np.save(temp_name,embedding_matrix)\n",
    "else:\n",
    "    embedding_matrix = np.load(temp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data,ids,isTest,t,max_head,max_body):\n",
    "    \n",
    "    from keras.utils.np_utils import to_categorical\n",
    "    head = list()\n",
    "    body = list()\n",
    "    y = list()\n",
    "    NUM_CLASSES = 4\n",
    "    category_dict = {'unrelated': 0 , 'agree':1, 'disagree':2, 'discuss':3}\n",
    "    for stance in data.stances:\n",
    "        if(isTest):\n",
    "            head.append(preprocess(stance['Headline'],head_stop,head_summary))\n",
    "            body.append(preprocess(data.articles[int(stance['Body ID'])],body_stop,body_summary))\n",
    "            y.append(category_dict[stance['Stance']])\n",
    "            continue\n",
    "        \n",
    "        if stance['Body ID'] not in ids:\n",
    "            continue\n",
    "        \n",
    "        head.append(preprocess(stance['Headline'],head_stop,head_summary))\n",
    "        body.append(preprocess(data.articles[int(stance['Body ID'])],body_stop,body_summary))\n",
    "        y.append(category_dict[stance['Stance']])\n",
    "    \n",
    "    head = t.texts_to_sequences(head)\n",
    "    body = t.texts_to_sequences(body)\n",
    "    head = pad_sequences(head,maxlen = max_head,padding = 'post')\n",
    "    body = pad_sequences(body,maxlen = max_body,padding = 'post')\n",
    "    y_cat = np.zeros((len(y),NUM_CLASSES))\n",
    "    y_cat = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "    return head,body,y_cat\n",
    "\n",
    "def create_labels(data):\n",
    "\n",
    "#     Usage\n",
    "#     y_train = create_labels(train_dataset)\n",
    "#     y_test = create_labels(test_dataset)\n",
    "\n",
    "    from keras.utils.np_utils import to_categorical\n",
    "    category_dict = {'unrelated': 0 , 'agree':1, 'disagree':2, 'discuss':3}\n",
    "    y = list()\n",
    "    NUM_CLASSES = 4\n",
    "    for stance in data.stances:\n",
    "        y.append(category_dict[stance['Stance']])\n",
    "\n",
    "    y_cat = np.zeros((len(y),NUM_CLASSES))\n",
    "    y_cat = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "    return y_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_text,train_body,y_train) = create_dataset(train_dataset,None,True,t,max_head,max_body)\n",
    "(test_text,test_body,y_test) = create_dataset(test_dataset,None,True,t,max_head,max_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49972\n",
      "30\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "print(len(train_text))\n",
    "print(len(test_text[0]))\n",
    "print(len(train_body[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 5000\n",
    "def create_hand_features(feat_fn,data,ids,isTest,name):\n",
    "    head = list()\n",
    "    body = list()\n",
    "    for stance in data.stances:\n",
    "        if(isTest):\n",
    "            head.append(stance['Headline'])\n",
    "            body.append(data.articles[int(stance['Body ID'])])\n",
    "            continue\n",
    "        \n",
    "        if stance['Body ID'] not in ids:\n",
    "            continue\n",
    "        \n",
    "        head.append(stance['Headline'])\n",
    "        body.append(data.articles[int(stance['Body ID'])])\n",
    "    \n",
    "    \n",
    "    features = feature_engineering.gen_or_load_feats(feat_fn, head ,body, './fnc-1/'+str(feat_fn.__name__)+name+'.npy')\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_simplified_data(data):\n",
    "    head = list()\n",
    "    body = list()\n",
    "    for stance in data.stances:\n",
    "        head.append(stance['Headline'])\n",
    "        body.append(data.articles[int(stance['Body ID'])])\n",
    "    return (head,body)\n",
    "def get_unique_head(dataset):\n",
    "    \n",
    "    head = list()\n",
    "    for stance in dataset.stances:\n",
    "        if stance['Headline'] not in head:\n",
    "            head.append(stance['Headline'])\n",
    "    return head\n",
    "\n",
    "def get_unique_body(dataset):\n",
    "    \n",
    "    body = list()\n",
    "    for i in dataset.articles.keys():\n",
    "        body.append(dataset.articles[i])\n",
    "\n",
    "    return body\n",
    "\n",
    "def get_tf_features(train_dataset,test_dataset):\n",
    "    \n",
    "    train_head,train_body = get_simplified_data(train_dataset)\n",
    "    test_head,test_body = get_simplified_data(test_dataset)\n",
    "    \n",
    "    train_unique_head = get_unique_head(train_dataset)\n",
    "    train_unique_body = get_unique_body(train_dataset)\n",
    "    test_unique_head = get_unique_head(test_dataset)\n",
    "    test_unique_body = get_unique_body(test_dataset)\n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    bow_vectorizer = CountVectorizer(max_features=num_words, stop_words='english')\n",
    "    bow = bow_vectorizer.fit_transform(train_unique_head + train_unique_body)\n",
    "    tfreq_vectorizer = TfidfTransformer(use_idf=False).fit(bow)\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=num_words, stop_words='english').fit(train_unique_head + train_unique_body+test_unique_body+test_unique_head)\n",
    "    \n",
    "    train_head_features_tf = list()\n",
    "    train_body_features_tf = list()\n",
    "    train_cosine = list()\n",
    "    head_dict = dict()\n",
    "    body_dict = dict()\n",
    "    \n",
    "    \n",
    "    for stance in train_dataset.stances:\n",
    "        heading = stance['Headline']\n",
    "        body = train_dataset.articles[int(stance['Body ID'])]\n",
    "        if heading not in head_dict:\n",
    "            head_dict[heading] = (tfreq_vectorizer.transform(bow_vectorizer.transform([heading])).toarray(),tfidf_vectorizer.transform([heading]).toarray())\n",
    "        if body not in body_dict:\n",
    "            body_dict[body] = (tfreq_vectorizer.transform(bow_vectorizer.transform([body])).toarray(),tfidf_vectorizer.transform([body]).toarray())\n",
    "        \n",
    "        train_head_features_tf.append(head_dict[heading][0])\n",
    "        train_body_features_tf.append(body_dict[body][0])\n",
    "        train_cosine.append(cosine_similarity(head_dict[heading][1],body_dict[body][1]))\n",
    "    \n",
    "    test_head_features_tf = list()\n",
    "    test_body_features_tf = list()\n",
    "    test_cosine = list()\n",
    "    head_dict = dict()\n",
    "    body_dict = dict()\n",
    "    for stance in test_dataset.stances:\n",
    "        heading = stance['Headline']\n",
    "        body = test_dataset.articles[int(stance['Body ID'])]\n",
    "        if heading not in head_dict:\n",
    "            head_dict[heading] = (tfreq_vectorizer.transform(bow_vectorizer.transform([heading])).toarray(),tfidf_vectorizer.transform([heading]).toarray())\n",
    "        if body not in body_dict:\n",
    "            body_dict[body] = (tfreq_vectorizer.transform(bow_vectorizer.transform([body])).toarray(),tfidf_vectorizer.transform([body]).toarray())\n",
    "        \n",
    "        test_head_features_tf.append(head_dict[heading][0])\n",
    "        test_body_features_tf.append(body_dict[body][0])\n",
    "        test_cosine.append(cosine_similarity(head_dict[heading][1],body_dict[body][1]))\n",
    "    \n",
    "    \n",
    "    return (train_head_features_tf,train_body_features_tf,train_cosine,test_head_features_tf,test_body_features_tf,test_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand Features\n",
    "train_features = np.hstack([create_hand_features(feature_engineering.hand_features,train_dataset,None,True,'trainFull'),\n",
    "                            create_hand_features(feature_engineering.word_overlap_features,train_dataset,None,True,'trainFull'),\n",
    "                            create_hand_features(feature_engineering.refuting_features,train_dataset,None,True,'trainFull'),\n",
    "                            create_hand_features(feature_engineering.polarity_features,train_dataset,None,True,'trainFull')])\n",
    "\n",
    "test_features = np.hstack([create_hand_features(feature_engineering.hand_features,test_dataset,None,True,'testFull'),\n",
    "                            create_hand_features(feature_engineering.word_overlap_features,test_dataset,None,True,'testFull'),\n",
    "                            create_hand_features(feature_engineering.refuting_features,test_dataset,None,True,'testFull'),\n",
    "                            create_hand_features(feature_engineering.polarity_features,test_dataset,None,True,'testFull')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = create_labels(train_dataset)\n",
    "y_test = create_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_head_features_tf,train_body_features_tf,train_cosine,test_head_features_tf,test_body_features_tf,test_cosine) = get_tf_features(train_dataset,test_dataset)\n",
    "\n",
    "def reshaping(temp):\n",
    "    t1 = np.array(temp)\n",
    "    t1 = np.reshape(t1,[t1.shape[0],t1.shape[2]])\n",
    "    return t1\n",
    "\n",
    "train_head_features_tf = reshaping(train_head_features_tf)\n",
    "train_body_features_tf = reshaping(train_body_features_tf)\n",
    "train_cosine = reshaping(train_cosine)\n",
    "test_head_features_tf = reshaping(test_head_features_tf)\n",
    "test_body_features_tf = reshaping(test_body_features_tf)\n",
    "test_cosine = reshaping(test_cosine)\n",
    "train_tf_features = np.hstack([train_head_features_tf, train_cosine, train_body_features_tf])\n",
    "test_tf_features = np.hstack([test_head_features_tf, test_cosine, test_body_features_tf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment_features = np.load('train_features_sentiment.npy')\n",
    "test_sentiment_features = np.load('test_features_sentiment.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras Import Statements\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Embedding, Input, Lambda\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalMaxPooling1D, AveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import concatenate,dot\n",
    "from keras.preprocessing import sequence\n",
    "import keras.backend as K\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answer(model,model_inp, true):\n",
    "    inv_category_dict = {0:'unrelated', 1: 'agree', 2: 'disagree', 3: 'discuss'}\n",
    "    predicted = model.predict(model_inp)\n",
    "    predicted = np.argmax(predicted,axis = 1)\n",
    "    t = np.argmax(true,axis = 1)\n",
    "    ground = list()\n",
    "    pred = list()\n",
    "    for i in predicted:\n",
    "        pred.append(inv_category_dict[i])\n",
    "    for i in t:\n",
    "        ground.append(inv_category_dict[i])\n",
    "    score.report_score(ground, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Layer\n",
    "def adder(x):\n",
    "    x = K.mean(x, axis=1)\n",
    "    # x = K.reshape(x,(K.shape(x)[0],K.shape(x)[-1]))\n",
    "    return x\n",
    "\n",
    "def adder_output(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3  # only valid for 3D tensors\n",
    "    shape = (shape[0],shape[2])\n",
    "    return tuple(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "head_input (InputLayer)         (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "body_input (InputLayer)         (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         multiple             8513700     head_input[0][0]                 \n",
      "                                                                 body_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128)          186880      embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 128)          186880      embedding_7[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_7 (Dot)                     (None, 1)            0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 257)          0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 dot_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 100)          25800       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 100)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 4)            404         dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 8,913,664\n",
      "Trainable params: 399,964\n",
      "Non-trainable params: 8,513,700\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 752.00 556.00\" width=\"752pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-552 748,-552 748,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139843918373664 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139843918373664</title>\n",
       "<polygon fill=\"none\" points=\"178,-511.5 178,-547.5 363,-547.5 363,-511.5 178,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270.5\" y=\"-525.8\">head_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139843918830000 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139843918830000</title>\n",
       "<polygon fill=\"none\" points=\"270,-438.5 270,-474.5 473,-474.5 473,-438.5 270,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"371.5\" y=\"-452.8\">embedding_7: Embedding</text>\n",
       "</g>\n",
       "<!-- 139843918373664&#45;&gt;139843918830000 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139843918373664-&gt;139843918830000</title>\n",
       "<path d=\"M295.4663,-511.4551C308.3342,-502.1545 324.2038,-490.6844 338.1102,-480.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"340.4164,-483.2849 346.4709,-474.5904 336.3159,-477.6116 340.4164,-483.2849\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139843918374056 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139843918374056</title>\n",
       "<polygon fill=\"none\" points=\"381,-511.5 381,-547.5 566,-547.5 566,-511.5 381,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473.5\" y=\"-525.8\">body_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139843918374056&#45;&gt;139843918830000 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139843918374056-&gt;139843918830000</title>\n",
       "<path d=\"M448.2865,-511.4551C435.2912,-502.1545 419.2645,-490.6844 405.2204,-480.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"406.9459,-477.5641 396.7769,-474.5904 402.8719,-483.2565 406.9459,-477.5641\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139843918370240 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>139843918370240</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 363,-401.5 363,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181.5\" y=\"-379.8\">bidirectional_1(head_lstm): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 139843918830000&#45;&gt;139843918370240 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>139843918830000-&gt;139843918370240</title>\n",
       "<path d=\"M324.5337,-438.4551C298.3855,-428.4087 265.6489,-415.8309 238.0952,-405.2445\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"239.1745,-401.9098 228.5845,-401.5904 236.6639,-408.4441 239.1745,-401.9098\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139843919565768 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>139843919565768</title>\n",
       "<polygon fill=\"none\" points=\"381,-365.5 381,-401.5 744,-401.5 744,-365.5 381,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-379.8\">bidirectional_2(body_lstm): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 139843918830000&#45;&gt;139843919565768 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>139843918830000-&gt;139843919565768</title>\n",
       "<path d=\"M418.7135,-438.4551C444.9993,-428.4087 477.9082,-415.8309 505.607,-405.2445\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"507.0762,-408.4299 515.1677,-401.5904 504.5771,-401.8912 507.0762,-408.4299\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139842992643208 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>139842992643208</title>\n",
       "<polygon fill=\"none\" points=\"384,-292.5 384,-328.5 475,-328.5 475,-292.5 384,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"429.5\" y=\"-306.8\">dot_7: Dot</text>\n",
       "</g>\n",
       "<!-- 139843918370240&#45;&gt;139842992643208 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>139843918370240-&gt;139842992643208</title>\n",
       "<path d=\"M242.8034,-365.4551C283.0017,-353.6225 335.1294,-338.2785 374.0834,-326.8122\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"375.0831,-330.1664 383.6878,-323.985 373.1064,-323.4513 375.0831,-330.1664\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139843920150312 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>139843920150312</title>\n",
       "<polygon fill=\"none\" points=\"319,-219.5 319,-255.5 540,-255.5 540,-219.5 319,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"429.5\" y=\"-233.8\">concatenate_6: Concatenate</text>\n",
       "</g>\n",
       "<!-- 139843918370240&#45;&gt;139843920150312 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>139843918370240-&gt;139843920150312</title>\n",
       "<path d=\"M212.1584,-365.4511C257.0549,-339.0201 340.7011,-289.7768 390.1028,-260.6935\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"392.0697,-263.5971 398.9116,-255.5077 388.5184,-257.5648 392.0697,-263.5971\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139843919565768&#45;&gt;139842992643208 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>139843919565768-&gt;139842992643208</title>\n",
       "<path d=\"M529.6236,-365.4551C512.0392,-355.8035 490.1984,-343.8156 471.407,-333.5016\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"472.9096,-330.3338 462.4591,-328.5904 469.5414,-336.4702 472.9096,-330.3338\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139843919565768&#45;&gt;139843920150312 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>139843919565768-&gt;139843920150312</title>\n",
       "<path d=\"M547.4164,-365.2975C531.7761,-346.5992 506.4454,-316.8035 483.5,-292 474.5255,-282.2988 464.3961,-271.9308 455.355,-262.8702\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"457.6209,-260.1871 448.0658,-255.6101 452.6811,-265.1468 457.6209,-260.1871\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139842992643208&#45;&gt;139843920150312 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>139842992643208-&gt;139843920150312</title>\n",
       "<path d=\"M429.5,-292.4551C429.5,-284.3828 429.5,-274.6764 429.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"433.0001,-265.5903 429.5,-255.5904 426.0001,-265.5904 433.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139842893757520 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>139842893757520</title>\n",
       "<polygon fill=\"none\" points=\"361,-146.5 361,-182.5 498,-182.5 498,-146.5 361,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"429.5\" y=\"-160.8\">dense_11: Dense</text>\n",
       "</g>\n",
       "<!-- 139843920150312&#45;&gt;139842893757520 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>139843920150312-&gt;139842893757520</title>\n",
       "<path d=\"M429.5,-219.4551C429.5,-211.3828 429.5,-201.6764 429.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"433.0001,-192.5903 429.5,-182.5904 426.0001,-192.5904 433.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139842893441568 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>139842893441568</title>\n",
       "<polygon fill=\"none\" points=\"346.5,-73.5 346.5,-109.5 512.5,-109.5 512.5,-73.5 346.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"429.5\" y=\"-87.8\">dropout_14: Dropout</text>\n",
       "</g>\n",
       "<!-- 139842893757520&#45;&gt;139842893441568 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>139842893757520-&gt;139842893441568</title>\n",
       "<path d=\"M429.5,-146.4551C429.5,-138.3828 429.5,-128.6764 429.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"433.0001,-119.5903 429.5,-109.5904 426.0001,-119.5904 433.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139842893868280 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>139842893868280</title>\n",
       "<polygon fill=\"none\" points=\"361,-.5 361,-36.5 498,-36.5 498,-.5 361,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"429.5\" y=\"-14.8\">dense_12: Dense</text>\n",
       "</g>\n",
       "<!-- 139842893441568&#45;&gt;139842893868280 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>139842893441568-&gt;139842893868280</title>\n",
       "<path d=\"M429.5,-73.4551C429.5,-65.3828 429.5,-55.6764 429.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"433.0001,-46.5903 429.5,-36.5904 426.0001,-46.5904 433.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_input = Input(shape=(max_head,), dtype='int32', name='head_input')\n",
    "body_input = Input(shape=(max_body,), dtype='int32', name='body_input')\n",
    "shared_embed = Embedding(len(word_index) + 1,EMBEDDING_DIM,weights=[embedding_matrix],trainable=False)\n",
    "head_embed = shared_embed(head_input)\n",
    "body_embed = shared_embed(body_input)\n",
    "\n",
    "head_lstm = Bidirectional(LSTM(64,dropout=0.2, recurrent_dropout=0.2, name='head_lstm'))(head_embed)\n",
    "body_lstm = Bidirectional(LSTM(64,dropout=0.2, recurrent_dropout=0.2, name='body_lstm'))(body_embed)\n",
    "dot_layer = dot([head_lstm,body_lstm],axes = 1, normalize=True)\n",
    "\n",
    "conc = concatenate([head_lstm,body_lstm,dot_layer])\n",
    "\n",
    "dense = Dense(100,activation='relu')(conc)\n",
    "dense = Dropout(0.3)(dense)\n",
    "dense = Dense(4,activation='softmax')(dense)\n",
    "model = Model(inputs=[head_input,body_input], outputs=[dense])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n",
    "print(model.summary())\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_final.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 178s 4ms/step - loss: 0.6943 - acc: 0.7474 - val_loss: 0.7205 - val_acc: 0.7284\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 174s 3ms/step - loss: 0.4582 - acc: 0.8229 - val_loss: 0.7036 - val_acc: 0.7242\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 175s 3ms/step - loss: 0.3125 - acc: 0.8816 - val_loss: 0.7091 - val_acc: 0.7445\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 175s 3ms/step - loss: 0.2269 - acc: 0.9145 - val_loss: 0.7482 - val_acc: 0.7523\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    653    |     6     |    499    |    745    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    151    |     3     |    182    |    361    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    680    |     3     |   2386    |   1395    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    716    |     3     |   1555    |   16075   |\n",
      "-------------------------------------------------------------\n",
      "Score: 7441.0 out of 11651.25\t(63.86439223259307%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 177s 4ms/step - loss: 0.1774 - acc: 0.9328 - val_loss: 0.8055 - val_acc: 0.7452\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 177s 4ms/step - loss: 0.1466 - acc: 0.9456 - val_loss: 0.8097 - val_acc: 0.7510\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 178s 4ms/step - loss: 0.1205 - acc: 0.9555 - val_loss: 0.8929 - val_acc: 0.7540\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 178s 4ms/step - loss: 0.1055 - acc: 0.9600 - val_loss: 0.9498 - val_acc: 0.7554\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    663    |     8     |    547    |    685    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    137    |     2     |    187    |    371    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    705    |     2     |   2382    |   1375    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    828    |     9     |   1361    |   16151   |\n",
      "-------------------------------------------------------------\n",
      "Score: 7481.25 out of 11651.25\t(64.20984872867719%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 177s 4ms/step - loss: 0.0897 - acc: 0.9663 - val_loss: 0.9711 - val_acc: 0.7691\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 177s 4ms/step - loss: 0.0797 - acc: 0.9694 - val_loss: 1.0192 - val_acc: 0.7653\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 178s 4ms/step - loss: 0.0705 - acc: 0.9728 - val_loss: 1.0590 - val_acc: 0.7624\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 177s 4ms/step - loss: 0.0637 - acc: 0.9750 - val_loss: 1.0379 - val_acc: 0.7677\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    564    |     9     |    595    |    735    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    129    |    10     |    193    |    365    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    624    |    20     |   2520    |   1300    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    531    |    37     |   1366    |   16415   |\n",
      "-------------------------------------------------------------\n",
      "Score: 7590.25 out of 11651.25\t(65.14537066838322%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 178s 4ms/step - loss: 0.0577 - acc: 0.9780 - val_loss: 1.1779 - val_acc: 0.7668\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 177s 4ms/step - loss: 0.0527 - acc: 0.9799 - val_loss: 1.2335 - val_acc: 0.7652\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 177s 4ms/step - loss: 0.0483 - acc: 0.9812 - val_loss: 1.2502 - val_acc: 0.7664\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 177s 4ms/step - loss: 0.0434 - acc: 0.9829 - val_loss: 1.2762 - val_acc: 0.7677\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    583    |    10     |    466    |    844    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    114    |    10     |    141    |    432    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    661    |     3     |   2147    |   1653    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    508    |    22     |   1050    |   16769   |\n",
      "-------------------------------------------------------------\n",
      "Score: 7281.0 out of 11651.25\t(62.49114901834567%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 177s 4ms/step - loss: 0.0406 - acc: 0.9845 - val_loss: 1.2917 - val_acc: 0.7660\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 176s 4ms/step - loss: 0.0368 - acc: 0.9854 - val_loss: 1.3581 - val_acc: 0.7660\n",
      "Epoch 3/4\n",
      "35712/49972 [====================>.........] - ETA: 41s - loss: 0.0351 - acc: 0.9869"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-3789bc5a1687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_body\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_body\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mevaluate_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_body\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model.fit([train_text,train_body],[y_train],validation_data = ([test_text,test_body],y_test),epochs=4, batch_size=128,verbose = True)\n",
    "    evaluate_answer(model,[test_text,test_body],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 175s 3ms/step - loss: 0.2782 - acc: 0.8860 - val_loss: 0.9690 - val_acc: 0.7022\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 175s 4ms/step - loss: 0.2526 - acc: 0.8974 - val_loss: 0.9753 - val_acc: 0.7030\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 176s 4ms/step - loss: 0.2355 - acc: 0.9043 - val_loss: 1.0509 - val_acc: 0.6934\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 176s 4ms/step - loss: 0.2320 - acc: 0.9057 - val_loss: 1.1099 - val_acc: 0.7071\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    756    |     0     |    390    |    757    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    240    |     0     |    167    |    290    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    778    |     0     |   2137    |   1549    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |   1430    |     0     |   1843    |   15076   |\n",
      "-------------------------------------------------------------\n",
      "Score: 7055.75 out of 11651.25\t(60.557880055788004%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 176s 4ms/step - loss: 0.2148 - acc: 0.9146 - val_loss: 1.0813 - val_acc: 0.6979\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 175s 4ms/step - loss: 0.2024 - acc: 0.9205 - val_loss: 1.0628 - val_acc: 0.7058\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 175s 4ms/step - loss: 0.1866 - acc: 0.9261 - val_loss: 1.1791 - val_acc: 0.7050\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 176s 4ms/step - loss: 0.1810 - acc: 0.9287 - val_loss: 1.0901 - val_acc: 0.7113\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    751    |     0     |    407    |    745    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    200    |     0     |    185    |    312    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    870    |     0     |   2051    |   1543    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |   1393    |     0     |   1681    |   15275   |\n",
      "-------------------------------------------------------------\n",
      "Score: 7036.25 out of 11651.25\t(60.390516039051604%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 174s 3ms/step - loss: 0.1718 - acc: 0.9338 - val_loss: 1.1224 - val_acc: 0.7057\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 175s 4ms/step - loss: 0.1635 - acc: 0.9358 - val_loss: 1.2376 - val_acc: 0.6846\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 174s 3ms/step - loss: 0.1522 - acc: 0.9409 - val_loss: 1.2368 - val_acc: 0.7085\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 175s 4ms/step - loss: 0.1446 - acc: 0.9447 - val_loss: 1.2413 - val_acc: 0.7046\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    788    |     0     |    466    |    649    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    256    |     0     |    179    |    262    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    960    |     0     |   2054    |   1450    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |   1571    |     1     |   1713    |   15064   |\n",
      "-------------------------------------------------------------\n",
      "Score: 7073.25 out of 11651.25\t(60.70807853234631%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 176s 4ms/step - loss: 0.1389 - acc: 0.9465 - val_loss: 1.3583 - val_acc: 0.7106\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 174s 3ms/step - loss: 0.1372 - acc: 0.9475 - val_loss: 1.2933 - val_acc: 0.7088\n",
      "Epoch 3/4\n",
      "32576/49972 [==================>...........] - ETA: 52s - loss: 0.1326 - acc: 0.9491"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fd285db0144b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_body\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_body\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mevaluate_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_body\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model.fit([train_text,train_body],[y_train],validation_data = ([test_text,test_body],y_test),epochs=4, batch_size=64,verbose = True)\n",
    "    evaluate_answer(model,[test_text,test_body],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "head_input (InputLayer)         (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "body_input (InputLayer)         (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        multiple             8513700     head_input[0][0]                 \n",
      "                                                                 body_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 200)          320800      embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 300)          0           embedding_11[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 500)          0           bidirectional_6[0][0]            \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 100)          50100       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 100)          0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 4)            404         dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 8,885,004\n",
      "Trainable params: 371,304\n",
      "Non-trainable params: 8,513,700\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "head_input = Input(shape=(max_head,), dtype='int32', name='head_input')\n",
    "body_input = Input(shape=(max_body,), dtype='int32', name='body_input')\n",
    "shared_embed = Embedding(len(word_index) + 1,EMBEDDING_DIM,weights=[embedding_matrix],trainable=False)\n",
    "head_embed = shared_embed(head_input)\n",
    "body_embed = shared_embed(body_input)\n",
    "\n",
    "head_lstm = Bidirectional(LSTM(100,dropout=0.2, recurrent_dropout=0.2, name='head_lstm'))(head_embed)\n",
    "body_embed = Lambda(adder,output_shape = adder_output)(body_embed)\n",
    "#dot_layer = dot([head_lstm,body_embed],axes = 1, normalize=True)\n",
    "\n",
    "conc = concatenate([head_lstm,body_embed])\n",
    "\n",
    "dense = Dense(100,activation='relu')(conc)\n",
    "dense = Dropout(0.4)(dense)\n",
    "dense = Dense(4,activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=[head_input,body_input], outputs=[dense])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 161s 3ms/step - loss: 0.7476 - acc: 0.7330 - val_loss: 0.7659 - val_acc: 0.7237\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 149s 3ms/step - loss: 0.6314 - acc: 0.7498 - val_loss: 0.7292 - val_acc: 0.7357\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 223s 4ms/step - loss: 0.5504 - acc: 0.7773 - val_loss: 0.7082 - val_acc: 0.7438\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 216s 4ms/step - loss: 0.4850 - acc: 0.8044 - val_loss: 0.7049 - val_acc: 0.7493\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    51     |     1     |    90     |   1761    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |     8     |     1     |     9     |    679    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    72     |     0     |   1055    |   3337    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    25     |     0     |    389    |   17935   |\n",
      "-------------------------------------------------------------\n",
      "Score: 5635.75 out of 11651.25\t(48.37034652934234%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 159s 3ms/step - loss: 0.4342 - acc: 0.8252 - val_loss: 0.6927 - val_acc: 0.7528\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 153s 3ms/step - loss: 0.3946 - acc: 0.8453 - val_loss: 0.6921 - val_acc: 0.7511\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 152s 3ms/step - loss: 0.3615 - acc: 0.8564 - val_loss: 0.6919 - val_acc: 0.7522\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 153s 3ms/step - loss: 0.3358 - acc: 0.8671 - val_loss: 0.6900 - val_acc: 0.7571\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    334    |     4     |    259    |   1306    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    55     |     1     |    69     |    572    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    305    |     0     |   1591    |   2568    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    376    |     0     |    660    |   17313   |\n",
      "-------------------------------------------------------------\n",
      "Score: 6427.25 out of 11651.25\t(55.163609054822444%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 168s 3ms/step - loss: 0.3130 - acc: 0.8772 - val_loss: 0.7085 - val_acc: 0.7576\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 151s 3ms/step - loss: 0.2928 - acc: 0.8859 - val_loss: 0.7618 - val_acc: 0.7603\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 150s 3ms/step - loss: 0.2765 - acc: 0.8924 - val_loss: 0.7419 - val_acc: 0.7577\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 184s 4ms/step - loss: 0.2634 - acc: 0.8993 - val_loss: 0.7246 - val_acc: 0.7622\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    516    |     3     |    217    |   1167    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    86     |     8     |    37     |    566    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    489    |     8     |   1614    |   2353    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    479    |     2     |    636    |   17232   |\n",
      "-------------------------------------------------------------\n",
      "Score: 6656.0 out of 11651.25\t(57.12691771269177%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 152s 3ms/step - loss: 0.2502 - acc: 0.9016 - val_loss: 0.7432 - val_acc: 0.7643\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 163s 3ms/step - loss: 0.2399 - acc: 0.9067 - val_loss: 0.7481 - val_acc: 0.7598\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 165s 3ms/step - loss: 0.2293 - acc: 0.9105 - val_loss: 0.7650 - val_acc: 0.7694\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 178s 4ms/step - loss: 0.2195 - acc: 0.9143 - val_loss: 0.7749 - val_acc: 0.7617\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    482    |     0     |    269    |   1152    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    96     |     4     |    82     |    515    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    489    |     6     |   1972    |   1997    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    434    |     4     |   1011    |   16900   |\n",
      "-------------------------------------------------------------\n",
      "Score: 6918.5 out of 11651.25\t(59.37989486106641%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 166s 3ms/step - loss: 0.2134 - acc: 0.9165 - val_loss: 0.7916 - val_acc: 0.7643\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 152s 3ms/step - loss: 0.2047 - acc: 0.9196 - val_loss: 0.8057 - val_acc: 0.7686\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 196s 4ms/step - loss: 0.1969 - acc: 0.9227 - val_loss: 0.8132 - val_acc: 0.7633\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 142s 3ms/step - loss: 0.1911 - acc: 0.9250 - val_loss: 0.8338 - val_acc: 0.7691\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    506    |     8     |    227    |   1162    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    97     |     6     |    57     |    537    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    479    |     9     |   1622    |   2354    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    431    |     8     |    498    |   17412   |\n",
      "-------------------------------------------------------------\n",
      "Score: 6706.25 out of 11651.25\t(57.558201909666344%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 96s 2ms/step - loss: 0.1818 - acc: 0.9301 - val_loss: 0.8268 - val_acc: 0.7695\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 97s 2ms/step - loss: 0.1775 - acc: 0.9306 - val_loss: 0.8933 - val_acc: 0.7670\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 92s 2ms/step - loss: 0.1732 - acc: 0.9311 - val_loss: 0.8852 - val_acc: 0.7665\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 81s 2ms/step - loss: 0.1690 - acc: 0.9342 - val_loss: 0.8815 - val_acc: 0.7686\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    518    |     3     |    268    |   1114    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    90     |    14     |    69     |    524    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    508    |    18     |   1911    |   2027    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    434    |    14     |    811    |   17090   |\n",
      "-------------------------------------------------------------\n",
      "Score: 6954.5 out of 11651.25\t(59.68887458427207%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 79s 2ms/step - loss: 0.1654 - acc: 0.9362 - val_loss: 0.8681 - val_acc: 0.7715\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 135s 3ms/step - loss: 0.1618 - acc: 0.9372 - val_loss: 0.8882 - val_acc: 0.7701\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 151s 3ms/step - loss: 0.1567 - acc: 0.9382 - val_loss: 0.9188 - val_acc: 0.7693\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 166s 3ms/step - loss: 0.1514 - acc: 0.9417 - val_loss: 0.9611 - val_acc: 0.7710\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    582    |     1     |    248    |   1072    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    112    |     8     |    65     |    512    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    603    |    11     |   1870    |   1980    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    523    |     4     |    688    |   17134   |\n",
      "-------------------------------------------------------------\n",
      "Score: 7003.5 out of 11651.25\t(60.10943031863534%)\n",
      "Train on 49972 samples, validate on 25413 samples\n",
      "Epoch 1/4\n",
      "49972/49972 [==============================] - 185s 4ms/step - loss: 0.1497 - acc: 0.9419 - val_loss: 0.9563 - val_acc: 0.7697\n",
      "Epoch 2/4\n",
      "49972/49972 [==============================] - 171s 3ms/step - loss: 0.1458 - acc: 0.9430 - val_loss: 0.9375 - val_acc: 0.7622\n",
      "Epoch 3/4\n",
      "49972/49972 [==============================] - 163s 3ms/step - loss: 0.1407 - acc: 0.9450 - val_loss: 1.0069 - val_acc: 0.7654\n",
      "Epoch 4/4\n",
      "49972/49972 [==============================] - 171s 3ms/step - loss: 0.1394 - acc: 0.9460 - val_loss: 1.0158 - val_acc: 0.7731\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    527    |     3     |    245    |   1128    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    107    |     9     |    64     |    517    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    484    |    17     |   1829    |   2134    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    371    |     5     |    691    |   17282   |\n",
      "-------------------------------------------------------------\n",
      "Score: 6915.5 out of 11651.25\t(59.35414655079927%)\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    model.fit([train_text,train_body],[y_train],validation_data = ([test_text,test_body],y_test),epochs=4, batch_size=64,verbose = True)\n",
    "    evaluate_answer(model,[test_text,test_body],y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
